name: llama.cpp - Full Optimized Binaries (Win + Linux + All Backends)

on:
  workflow_dispatch:
  push:
    branches: [ master, main ]

jobs:
  build:
    strategy:
      fail-fast: false
      matrix:
        include:
          # Windows CPU maksimal
          - name: win-avx512
            os: windows-latest
            cmake_flags: "-DGGML_AVX512=ON -DGGML_AVX2=ON -DGGML_AVX=ON -DGGML_F16C=ON -DGGML_FMA=ON"
            artifact: llama-win-avx512.exe

          # Windows CUDA full
          - name: win-cuda
            os: windows-latest
            cmake_flags: "-DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=all-major"
            artifact: llama-win-cuda.exe
            cuda: true

          # Linux CPU maksimal
          - name: linux-avx512
            os: ubuntu-latest
            cmake_flags: "-DGGML_AVX512=ON -DGGML_AVX2=ON -DGGML_AVX=ON -DGGML_F16C=ON -DGGML_FMA=ON -DGGML_NATIVE=ON"
            artifact: llama-linux-avx512

          # Linux CUDA full
          - name: linux-cuda
            os: ubuntu-latest
            cmake_flags: "-DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=all-major"
            artifact: llama-linux-cuda
            cuda: true

          # Linux Vulkan full
          - name: linux-vulkan
            os: ubuntu-latest
            cmake_flags: "-DGGML_VULKAN=ON -DGGML_NATIVE=ON"
            artifact: llama-linux-vulkan

    runs-on: ${{ matrix.os }}

    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Install Linux deps
        if: runner.os == 'Linux'
        run: |
          sudo apt update -qq
          sudo apt install -y build-essential cmake ninja-build libcurl4-openssl-dev libvulkan-dev glslc libshaderc-dev

      - name: Install CUDA (stable & working 2025)
        if: matrix.cuda
        uses: Jimver/cuda-toolkit@v0.2.29
        with:
          cuda: "12.6.2"
          method: network

      - name: Setup MSVC (Windows)
        if: runner.os == 'Windows'
        uses: ilammy/msvc-dev-cmd@v1

      - name: CMake Configure (FULL FEATURES - NO EXTRA FLAGS THAT BREAK)
        run: |
          cmake -B build -G Ninja \
            -DCMAKE_BUILD_TYPE=Release \
            -DLLAMA_BUILD_SERVER=ON \
            -DLLAMA_BUILD_EXAMPLES=ON \
            -DLLAMA_CURL=ON \
            ${{ matrix.cmake_flags }}

      - name: Build (max parallel - no broken flags)
        run: cmake --build build --config Release --parallel

      - name: Download UPX
        run: |
          curl -L -o upx.zip https://github.com/upx/upx/releases/download/v4.2.4/upx-4.2.4-${{ runner.os == 'Windows' && 'win64' || 'amd64_linux' }}.zip
          unzip -o upx.zip

      - name: Compress with UPX (ultra)
        continue-on-error: true
        run: |
          ./*/upx --best --lzma build/bin/llama-server.exe build/bin/llama-cli.exe 2>/dev/null || true
          ./*/upx --best --lzma build/bin/llama-server build/bin/llama-cli 2>/dev/null || true

      - name: Rename & pack
        run: |
          mkdir release
          cp build/bin/llama-server* release/${{ matrix.artifact }} || true
          cp build/bin/llama-cli*    release/llama-cli-${{ matrix.artifact }} || true

      - name: Upload
        uses: actions/upload-artifact@v4
        with:
          name: ${{ matrix.name }}
          path: release/*
