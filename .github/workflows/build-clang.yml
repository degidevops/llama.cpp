name: LLAMA.CPP FULL OPTIMIZED - 100% WORKING NOV 2025

on:
  workflow_dispatch:
  push:
    branches: [ master, main ]

jobs:
  build:
    strategy:
      fail-fast: false
      matrix:
        include:
          - name: Windows-AVX512
            os: windows-latest
            runner: windows-2025
            cmake_extra: "-DGGML_AVX512=ON -DGGML_AVX2=ON -DGGML_AVX=ON -DGGML_FMA=ON -DGGML_F16C=ON"
            artifact_suffix: win-avx512

          - name: Windows-CUDA
            os: windows-latest
            runner: windows-2025
            cmake_extra: "-DGGML_CUDA=ON -DGGML_CUDA_FORCE_CUBLAS=ON -DCMAKE_CUDA_ARCHITECTURES=all-major"
            artifact_suffix: win-cuda
            needs_cuda: true

          - name: Linux-AVX512
            os: ubuntu-latest
            runner: ubuntu-24.04
            cmake_extra: "-DGGML_AVX512=ON -DGGML_AVX2=ON -DGGML_AVX=ON -DGGML_FMA=ON -DGGML_F16C=ON -DGGML_NATIVE=ON"
            artifact_suffix: linux-avx512

          - name: Linux-CUDA
            os: ubuntu-latest
            runner: ubuntu-24.04
            cmake_extra: "-DGGML_CUDA=ON -DCMAKE_CUDA_ARCHITECTURES=all-major"
            artifact_suffix: linux-cuda
            needs_cuda: true

          - name: Linux-Vulkan
            os: ubuntu-latest
            runner: ubuntu-24.04
            cmake_extra: "-DGGML_VULKAN=ON -DGGML_NATIVE=ON"
            artifact_suffix: linux-vulkan

    runs-on: ${{ matrix.runner }}
    timeout-minutes: 120

    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          submodules: recursive

      - name: Install Linux dependencies (fix shaderc + glslc)
        if: runner.os == 'Linux'
        run: |
          sudo apt-get update -y
          sudo apt-get install -y build-essential cmake ninja-build \
            libcurl4-openssl-dev libssl-dev \
            libvulkan-dev vulkan-tools glslc libshaderc-dev

      - name: Setup vcpkg (Windows static curl)
        if: runner.os == 'Windows'
        shell: powershell
        run: |
          git clone https://github.com/microsoft/vcpkg.git C:\vcpkg
          C:\vcpkg\bootstrap-vcpkg.bat
          C:\vcpkg\vcpkg install curl[core,ssl]:x64-windows-static-md --recurse

      - name: Install CUDA Toolkit 12.6 (working action)
        if: matrix.needs_cuda
        uses: Jimver/cuda-toolkit@v0.2.29
        with:
          cuda: '12.6.2'
          method: network

      - name: Setup MSVC
        if: runner.os == 'Windows'
        uses: ilammy/msvc-dev-cmd@v1

      - name: Configure CMake (FULL FEATURES + FIX CUDA WINDOWS)
        shell: bash
        env:
          COMMON: >-
            -DCMAKE_BUILD_TYPE=Release -G Ninja
            -DBUILD_SHARED_LIBS=OFF
            -DLLAMA_BUILD_SERVER=ON -DLLAMA_BUILD_EXAMPLES=ON
            -DGGML_STATIC=ON -DGGML_LTO=ON
            -DLLAMA_CURL=ON
            -DLLAMA_SUPPORT_VISION=ON
            -DLLAMA_SUPPORT_EMBEDDING=ON
            -DLLAMA_SUPPORT_TOOLS=ON
            -DLLAMA_SUPPORT_INSERT=ON
        run: |
          cmake -B build \
            $COMMON \
            ${{ matrix.cmake_extra }} \
            ${{ runner.os == 'Windows' && '-DCMAKE_TOOLCHAIN_FILE=C:/vcpkg/scripts/buildsystems/vcpkg.cmake -DVCPKG_TARGET_TRIPLET=x64-windows-static-md' || '' }} \
            ${{ runner.os == 'Windows' && '-DCMAKE_C_FLAGS_RELEASE=\"/O2 /GL /arch:AVX512 /DNDEBUG\" -DCMAKE_CXX_FLAGS_RELEASE=\"/O2 /GL /arch:AVX512 /DNDEBUG\" -DCMAKE_EXE_LINKER_FLAGS=\"/LTCG /OPT:REF /OPT:ICF\"' || '' }} \
            ${{ runner.os == 'Linux' && '-DCMAKE_C_FLAGS=\"-O3 -march=native -mtune=native -flto=auto -ffat-lto-objects\" -DCMAKE_CXX_FLAGS=\"-O3 -march=native -mtune=native -flto=auto -ffat-lto-objects\"' || '' }}

      - name: Build (fix Windows parallel)
        shell: bash
        run: |
          if [[ "$RUNNER_OS" == "Windows" ]]; then
            cmake --build build --config Release --parallel $env:NUMBER_OF_PROCESSORS
          else
            cmake --build build --config Release -j $(nproc)
          fi

      - name: Download UPX
        run: |
          curl -L -o upx.zip https://github.com/upx/upx/releases/download/v4.2.4/upx-4.2.4-${{ runner.os == 'Windows' && 'win64' || 'amd64_linux' }}.zip
          unzip -o upx.zip
          chmod +x upx*/upx* 2>/dev/null || true

      - name: Compress binaries
        continue-on-error: true
        run: |
          ./upx*/upx* --best --lzma build/bin/llama-server* build/bin/llama-cli* || true

      - name: Prepare artifacts
        run: |
          mkdir release
          suffix="${{ matrix.artifact_suffix }}${{ runner.os == 'Windows' && '.exe' || '' }}"
          cp build/bin/llama-server* release/llama-server-$suffix 2>/dev/null || true
          cp build/bin/llama-cli*    release/llama-cli-$suffix 2>/dev/null || true
          ls -lh release/

      - name: Upload Artifacts
        uses: actions/upload-artifact@v4
        with:
          name: llama.cpp-${{ matrix.name }}
          path: release/*
